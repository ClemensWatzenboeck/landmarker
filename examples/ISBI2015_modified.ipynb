{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p align=\"center\">\n",
    "    <a href=\"https://predict-idlab.github.io/landmarker\">\n",
    "        <img alt=\"landmarker\" src=\"https://raw.githubusercontent.com/predict-idlab/landmarker/main/docs/_static/images/logo.svg\" width=\"66%\">\n",
    "    </a>\n",
    "</p>\n",
    "\n",
    "# Training and Evaluating Adaptive Heatmap Regression Model for Landmark Detection with ISBI 2015 Cephalometric X-ray Dataset\n",
    "\n",
    "In this tutorial, we will train and evaluate an adaptive heatmap regression model for landmark \n",
    "detection with the ISBI 2015 Cephalometric X-ray dataset. The ISBI 2015 Cephalometric X-ray dataset\n",
    "is a dataset of 2D cephalometric X-rays. The dataset contains 400 images, each with 19 landmarks\n",
    "annotated. The dataset is split into a training set of 150 images and two test sets of 150 and\n",
    "100 images respectively.\n",
    "\n",
    "We will go through the following steps:\n",
    "* [Loading the dataset](#Loading-the-dataset)\n",
    "* [Constructing a heatmap generator](#Constructing-a-heatmap-generator)\n",
    "* [Inspecting the dataset](#Inspecting-the-dataset)\n",
    "* [Training and initializing the SpatialConfiguration model](#Training-the-model)\n",
    "* [Evaluating the model](#Evaluating-the-model)\n",
    "\n",
    "<a target=\"_blank\" href=\"https://colab.research.google.com/github/predict-idlab/landmarker/examples/adaptive_scn_isbi2015.ipynb\">\n",
    "  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n",
    "</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "\n",
    "# !python -c \"import landmarker\" || pip install landmarker\n",
    "\n",
    "import sys\n",
    "import os\n",
    "import ra_utils.visualization.plot_landmarks #.plot_landmarks\n",
    "\n",
    "# sys.path.append(\"../src/\")\n",
    "import landmarker\n",
    "from landmarker.datasets import get_cepha_landmark_datasets, get_tiny_cepha_landmark_datasets\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import DataLoader\n",
    "from monai.transforms import (Compose, RandAffined, RandGaussianNoised, RandStdShiftIntensityd,\n",
    "                              RandScaleIntensityd, RandAdjustContrastd, RandHistogramShiftd,\n",
    "                              ScaleIntensityd, Lambdad, LoadImage, Transpose)\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import ra_utils\n",
    "import ra_utils.visualization\n",
    "import ra_utils.visualization.plot_landmarks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup imports and variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the dataset\n",
    "\n",
    "### Short description of the data and dataset module\n",
    "The [landmarker](https://github.com/predict-idlab/landmarker) package has several built-in\n",
    "datasets in the `landmarker.datasets` module, as well as utility classes for building your own\n",
    "datasets in the `landmarker.data` module. There are three types of datasets: 'LandmarkDataset',\n",
    "'HeatmapDataset', and 'MaskDataset'. The 'LandmarkDataset' is a dataset of images with landmarks,\n",
    "the 'HeatmapDataset' is a dataset of images with heatmaps, and the 'MaskDataset' is a dataset of\n",
    "images with masks (i.e., binary segmentation masks indiciating the location of the landmarks). The \n",
    "'HeatmapDataset' and 'MaskDataset' both inherit from the 'LandmarkDataset' class, and thus also \n",
    "contain information about the landmarks. The 'MaskDataset' can be constructed from specified image \n",
    "and landmarks pairs, or from images and masks pairs, because often that is how the data is\n",
    "distributed. The 'HeatmapDataset' can be constructed from images and landmarks pairs.\n",
    "\n",
    "Images can be provided as a list of paths to stored images, or as a a numpy arary, torch tensor, \n",
    "list of numpy  arrays or list of torch tensors. Landmarks can be as numpy arrays or torch tensors.\n",
    "These landmarks can be provided in three different shapes: (1) (N, D) where N is the number of\n",
    "samples and D is the number of dimensions, (2) (N, C, D) where C is the number of landmark\n",
    "classes, (3) (N, C, I, D) where I is the number of instances per landmark class, if less than I\n",
    "instances are provided, the remaining instances are filled with NaNs.\n",
    "\n",
    "For built-in datasets, the `landmarker.datasets` module provides a function for\n",
    "downloading and loading the dataset, e.g. `get_cepha_landmark_datasets` for the ISBI 2015 \n",
    "Cephalometric X-ray dataset. Most of these functions take the same arguments, namely `path_dir`,\n",
    "some are dataset specific. The `path_dir` argument specifies the directory where the dataset is\n",
    "downloaded to, or loaded from if it is already downloaded. For most datasets multiple functions\n",
    "are provided for getting different types of datasets. For example, the ISBI 2015 Cephalometric\n",
    "X-ray dataset has the following functions: `get_cepha_landmark_datasets` and \n",
    "`get_cepha_heatmap_datasets`.\n",
    "\n",
    "### Download and load ISBI 2015 landmark dataset\n",
    "The ISBI 2015 Cephalometric X-ray dataset is a dataset of 2D cephalometric X-ray images with 19\n",
    "landmarks. The dataset is split into a training set of 150 images and two test sets, where test\n",
    "set  1 contains 150 images and test set 2 contains 100 images. When loading the dataset, you can\n",
    "also specify a transform function, which is applied to the images and landmarks of the training\n",
    "set. Currently, we only support the `monai.transforms.ComposeD transform, which allows you to\n",
    "compose multiple transforms. The `monai.transforms` module contains many useful transforms, such\n",
    "as `RandomAffine` and `NormalizeIntensity`. The transforms must be dictionary transforms, i.e.,\n",
    "they must return a dictionary with the keys 'image' and ('seg'), in the case of heatmap and mask\n",
    "regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Data check\n",
    "# Is are the landmarks positioned as I expect prior to resizing? \n",
    "# Check a single image: \n",
    "\n",
    "\n",
    "data_dir = \"/home/clemens/data/public/landmark-datasets\"\n",
    "i=0\n",
    "lm_sample =  pd.read_csv(\n",
    "        data_dir + f\"/ISBI2015/400_junior/{str(i+1).zfill(3)}.txt\",\n",
    "        sep=\",\",\n",
    "        header=None,\n",
    "    )[:19].to_numpy()\n",
    "\n",
    "image_path = str(list(Path(data_dir + f\"/ISBI2015/RawImage/\").glob(f\"*/{str(i+1).zfill(3)}.bmp\"))[0])\n",
    "\n",
    "image = LoadImage(ensure_channel_first=True)(image_path)\n",
    "image = Transpose((0,2,1))(image)\n",
    "ra_utils.visualization.plot_landmarks.plot_landmarks(image[0,...].numpy(), \n",
    "                                                     landmarks=lm_sample, \n",
    "                                                     figsize=(4,3));\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "from landmarker.transforms.images import UseOnlyFirstChannel\n",
    "fn_keys = ('image',)\n",
    "spatial_transformd = [RandAffined(fn_keys, prob=1,\n",
    "                        rotate_range=(-np.pi/12, np.pi/12),\n",
    "                        translate_range=(-10, 10),\n",
    "                        scale_range=(-0.1, 0.1),\n",
    "                        shear_range=(-0.1, 0.1)\n",
    "                        )]\n",
    "\n",
    "train_transformd = Compose([\n",
    "                            UseOnlyFirstChannel(('image', )),\n",
    "                            RandGaussianNoised(('image', ), prob=0.2, mean=0, std=0.1),  # Add gaussian noise\n",
    "                            RandScaleIntensityd(('image', ), factors=0.25, prob=0.2),  # Add random intensity scaling\n",
    "                            RandAdjustContrastd(('image', ), prob=0.2, gamma=(0.5,4.5)),  # Randomly adjust contrast\n",
    "                            RandHistogramShiftd(('image', ), prob=0.2),  # Randomly shift histogram\n",
    "                            ScaleIntensityd(('image', )),  # Scale intensity\n",
    "                        ] + spatial_transformd)\n",
    "\n",
    "inference_transformd = Compose([\n",
    "    UseOnlyFirstChannel(('image', )),\n",
    "    ScaleIntensityd(('image', )),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "data_dir = \"/home/clemens/data/public/landmark-datasets\"\n",
    "ds_train, ds_test1, ds_test2 = get_tiny_cepha_landmark_datasets(\n",
    "    data_dir, train_transform=train_transformd,\n",
    "    inference_transform=inference_transformd,\n",
    "    store_imgs = True, dim_img=(512, 512),\n",
    "    junior = True, \n",
    "    N_train=2,\n",
    "    N_test1=2,\n",
    "    N_test2=2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = ds_train[0]\n",
    "\n",
    "image=X[\"image\"].numpy()[0,...]\n",
    "landmarks = X[\"landmark\"].numpy()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(4,3))\n",
    "ax.imshow(image, cmap='gray')\n",
    "ax.scatter(landmarks[:, 1], landmarks[:, 0], \n",
    "            s=20, color='red', marker='x')\n",
    "ax.axis(\"off\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constructing a heatmap generator\n",
    "The heatmap generator is a class that generates heatmaps from landmarks. It is used to generate\n",
    "heatmaps from the landmarks of the training set, which are then used to train the model. The\n",
    "`landmarker.heatmap_generator` module contains several heatmap generators, such as the\n",
    "`GaussianHeatmapGenerator` and `LaplaceHeatmapGenerator` which generate a multivariate \n",
    "Gaussian and Laplace distribution respectively. The HeatmapGenerator subclasses take the following\n",
    "arguments:\n",
    "* `sigmas`: the standard deviation of the Gaussian distribution, or the scale of the Laplace. This \n",
    "could be a scalar, or a list of scalars, one for each landmark class. Additionally, it could be a\n",
    "covariance matrix, or a list of covariance matrices, one for each landmark class.\n",
    "* `gamma`: If provided, the heatmaps are scaled by `gamma` before being returned.\n",
    "* `rotation`: If provided, the heatmaps are rotated by `rotation` before being returned.\n",
    "* `heatmap_size`: The size of the returned heatmaps.\n",
    "* learnable: If True, the `sigma` and `rotation` parameters are learnable parameters, and thus\n",
    "will be optimized during training.\n",
    "* `background`: A boolean indicating whether to add a background class to the heatmaps. If True,\n",
    "the heatmaps will have an additional channel, which is 1 everywhere except at the location of the\n",
    "landmarks, where it is 0. The background class is the first class, i.e., the first channel.\n",
    "* `all_points`: A boolean indicating whether to add a channel with all the landmarks. If True, the\n",
    "heatmaps will have an additional channel, which is 1 at the location of the landmarks, and 0.\n",
    "everywhere else.\n",
    "* `continuous`: A boolean indicating whether to use continuous or discrete landmarks.\n",
    "* `device`: The device on which the heatmaps are generated.\n",
    "\n",
    "The landmarks provide to the heatmap generator must be a torch.Tensor and can be in three different \n",
    "shapes: (1) (N, D) where N is the number of samples and D is the number of dimensions, (2) (N, C, D)\n",
    "where C is the number of landmark classes, (3) (N, C, I, D) where I is the number of instances per\n",
    "landmark class, if less than I instances are provided, the remaining instances are filled with NaNs.\n",
    "The heatmap generator will return a torch.Tensor of shape (N, C, H, W), where H and W are the height\n",
    "and width of the heatmaps respectively.\n",
    "\n",
    "**Note that with 2D landmarks the y coordinates are the first dimension, and the x coordinates are the\n",
    "second dimension.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from landmarker.heatmap.generator import GaussianHeatmapGenerator\n",
    "\n",
    "heatmap_generator = GaussianHeatmapGenerator(\n",
    "    nb_landmarks=19,\n",
    "    sigmas=3,\n",
    "    gamma=100,\n",
    "    heatmap_size=(512, 512),\n",
    "    learnable=True, # If True, the heatmap generator will be trainable\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inspecting the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from landmarker.visualize import inspection_plot\n",
    "\n",
    "# Plot the first 3 images from the training set\n",
    "inspection_plot(ds_train, range(2), heatmap_generator=heatmap_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the first 3 images from dataset without transforms\n",
    "heatmap_generator.device = \"cpu\" # because dataset tensors are still on cpu\n",
    "inspection_plot(ds_test1, 0, heatmap_generator=heatmap_generator)\n",
    "heatmap_generator.device = device # set the desired device back"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training and initializing the SpatialConfiguration model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initializing the model, optimizer and loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from landmarker.models.spatial_configuration_net import OriginalSpatialConfigurationNet\n",
    "from landmarker.losses import GaussianHeatmapL2Loss\n",
    "\n",
    "model = OriginalSpatialConfigurationNet(in_channels=1, out_channels=19).to(device)\n",
    "print(\"Number of learnable parameters: {}\".format(\n",
    "    sum(p.numel() for p in model.parameters() if p.requires_grad)))\n",
    "lr = 1e-6\n",
    "batch_size = 1\n",
    "epochs = 2\n",
    "\n",
    "optimizer = torch.optim.SGD([\n",
    "    {'params': model.parameters(), \"weight_decay\":1e-3},\n",
    "    {'params': heatmap_generator.sigmas},\n",
    "    {'params': heatmap_generator.rotation}]\n",
    "    , lr=lr, momentum=0.99, nesterov=True)\n",
    "\n",
    "\n",
    "criterion = GaussianHeatmapL2Loss(\n",
    "    alpha=5\n",
    ")\n",
    "\n",
    "lr_scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5,\n",
    "                                                          patience=10, verbose=True, cooldown=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting the data loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(ds_train, batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "val_loader = DataLoader(ds_test1, batch_size=batch_size, shuffle=False, num_workers=0)\n",
    "test_loader = DataLoader(ds_test2, batch_size=batch_size, shuffle=False, num_workers=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from landmarker.heatmap.decoder import heatmap_to_coord\n",
    "from landmarker.metrics import point_error\n",
    "\n",
    "def train_epoch(model, heatmap_generator, train_loader, criterion, optimizer, device):\n",
    "    running_loss = 0\n",
    "    model.train()\n",
    "    for i, batch in enumerate(tqdm(train_loader)):\n",
    "        images = batch[\"image\"].to(device)\n",
    "        landmarks = batch[\"landmark\"].to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        heatmaps = heatmap_generator(landmarks)\n",
    "        loss = criterion(outputs, heatmap_generator.sigmas, heatmaps)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "    return running_loss / len(train_loader)\n",
    "\n",
    "def val_epoch(model, heatmap_generator, val_loader, criterion, device, method=\"local_soft_argmax\"):\n",
    "    eval_loss = 0\n",
    "    eval_mpe = 0\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for i, batch in enumerate(tqdm(val_loader)):\n",
    "            images = batch[\"image\"].to(device)\n",
    "            landmarks = batch[\"landmark\"].to(device)\n",
    "            outputs = model(images)\n",
    "            dim_orig = batch[\"dim_original\"].to(device)\n",
    "            pixel_spacing = batch[\"spacing\"].to(device)\n",
    "            padding = batch[\"padding\"].to(device)\n",
    "            heatmaps = heatmap_generator(landmarks)\n",
    "            loss = criterion(outputs, heatmap_generator.sigmas, heatmaps)\n",
    "            pred_landmarks = heatmap_to_coord(outputs, method=method)\n",
    "            eval_loss += loss.item()\n",
    "            eval_mpe += point_error(landmarks, pred_landmarks, images.shape[-2:], dim_orig,\n",
    "                                    pixel_spacing, padding, reduction=\"mean\")\n",
    "    return eval_loss / len(val_loader), eval_mpe / len(val_loader)\n",
    "\n",
    "def train(model, heatmap_generator, train_loader, val_loader, criterion, optimizer, device, epochs=1000):\n",
    "    for epoch in tqdm(range(epochs)):\n",
    "        train_loss = train_epoch(model, heatmap_generator, train_loader, criterion, optimizer, device)\n",
    "        val_loss, val_mpe = val_epoch(model, heatmap_generator, val_loader, criterion, device)\n",
    "        print(f\"Epoch {epoch+1}/{epochs} - Train loss: {train_loss:.4f} - Val loss: {val_loss:.4f} - Val mpe: {val_mpe:.4f}\")\n",
    "        lr_scheduler.step(val_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train(model, heatmap_generator, train_loader, val_loader, criterion, optimizer, device,\n",
    "      epochs=epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_landmarks = []\n",
    "true_landmarks = []\n",
    "dim_origs = []\n",
    "pixel_spacings = []\n",
    "paddings = []\n",
    "test_mpe = 0\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for i, X in enumerate(tqdm(test_loader)):\n",
    "        images = X[\"image\"]\n",
    "        landmarks = X[\"landmark\"]\n",
    "        affine_matrix = X[\"affine\"]\n",
    "        dim_orig = X[\"dim_original\"] \n",
    "        pixel_spacing = X[\"spacing\"]\n",
    "        padding = X[\"padding\"]\n",
    "        \n",
    "        images = images.to(device)\n",
    "        landmarks = landmarks.to(device)\n",
    "        dim_orig = dim_orig.to(device)\n",
    "        pixel_spacing = pixel_spacing.to(device)\n",
    "        padding = padding.to(device)\n",
    "        outputs = model(images)\n",
    "        # heatmap = heatmap_generator(landmarks)\n",
    "        offset_coords = outputs.shape[1]-landmarks.shape[1]\n",
    "        pred_landmark = heatmap_to_coord(outputs, offset_coords=offset_coords,\n",
    "                                        method=\"local_soft_argmax\")\n",
    "        test_mpe += point_error(landmarks, pred_landmark, images.shape[-2:], dim_orig,\n",
    "                                pixel_spacing, padding, reduction=\"mean\")\n",
    "        pred_landmarks.append(pred_landmark.cpu())\n",
    "        true_landmarks.append(landmarks.cpu())\n",
    "        dim_origs.append(dim_orig.cpu())\n",
    "        pixel_spacings.append(pixel_spacing.cpu())\n",
    "        paddings.append(padding.cpu())\n",
    "\n",
    "pred_landmarks = torch.cat(pred_landmarks)\n",
    "true_landmarks = torch.cat(true_landmarks)\n",
    "dim_origs = torch.cat(dim_origs)\n",
    "pixel_spacings = torch.cat(pixel_spacings)\n",
    "paddings = torch.cat(paddings)\n",
    "\n",
    "test_mpe /= len(test_loader)\n",
    "\n",
    "print(f\"Test Mean PE: {test_mpe:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from landmarker.metrics import sdr\n",
    "\n",
    "sdr_test = sdr([2.0, 2.5, 3.0, 4.0], true_landmarks=true_landmarks, pred_landmarks=pred_landmarks,\n",
    "               dim=(512, 512), dim_orig=dim_origs.int(), pixel_spacing=pixel_spacings, padding=paddings)\n",
    "for key in sdr_test:\n",
    "    print(f\"SDR for {key}mm: {sdr_test[key]:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from landmarker.metrics import sdr\n",
    "\n",
    "sdr_test = sdr([2.0, 2.5, 3.0, 4.0], true_landmarks=true_landmarks, pred_landmarks=pred_landmarks,\n",
    "               dim=(512, 512), dim_orig=dim_origs.int(), pixel_spacing=pixel_spacings, padding=paddings)\n",
    "for key in sdr_test:\n",
    "    print(f\"SDR for {key}mm: {sdr_test[key]:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from landmarker.visualize.utils import prediction_inspect_plot\n",
    "\n",
    "model.eval()\n",
    "model.to(\"cpu\")\n",
    "prediction_inspect_plot(ds_test2, model, range(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from landmarker.visualize import detection_report\n",
    "\n",
    "detection_report(true_landmarks, pred_landmarks, dim=(512, 512), dim_orig=dim_origs.int(),\n",
    "                    pixel_spacing=pixel_spacings, padding=paddings, class_names=ds_train.class_names,\n",
    "                    radius=[2.0, 2.5, 3.0, 4.0], digits=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from landmarker.visualize import plot_cpe\n",
    "\n",
    "plot_cpe(true_landmarks, pred_landmarks, dim=(512, 512), dim_orig=dim_origs.int(),\n",
    "                    pixel_spacing=pixel_spacings, padding=paddings, class_names=ds_train.class_names,\n",
    "                    group=False, title=\"CPE curve\", save_path=None,\n",
    "                    stat='proportion', unit='mm', kind='ecdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py3-10_ra",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
